# digitalmarketplace-scripts

## A short overview of current scripts

This repository contains scripts that interact with the Digital Marketplace APIs (
[data API](https://github.com/alphagov/digitalmarketplace-api) and
[search-api](https://github.com/alphagov/digitalmarketplace-search-api)).

* `scripts/generate-user-email-list.py`
  script for generating a CSV of user email addresses and
  details in the Digital Marketplace.

* `scripts/index-services.py`
  Reads services from the API endpoint and writes to search-api for indexing.

* `scripts/generate-framework-agreement-data.py`
  Generates a tab-separated values file with the data required by CCS to populate
  the G-Cloud 7 framework agreements.  It uses the collated data from declaration
  and lot csv files generated by existing scripts in the API project:
  `generate_lots_export_for_ccs_sourcing` and
  `generate_declarations_export_for_ccs_sourcing`.

* `scripts/insert-framework-results.py`
  Reads a csv file of results for suppliers who have/have not been accepted onto
  a framework and posts to the API to set the `on_framework` value in the
  `supplier_frameworks` table.

* `scripts/generate-pdf-import-data.py`
  Reads the successful.csv file generated by `scripts/export-dos-suppliers.py`
  and generates a .txt file (in TSV format) to be used as import data when
  creating PDF result letters or framework agreements.


## A general approach to writing new scripts

Historically (and currently), this respository has been filled with small files that slightly diverge from one another. The idea has been that scripts are written for things that happen once (slash infrequently) in the lifecycle of a framework -- so we write our script, run it once, and then walk away.

This is a good thing. It means we have a cleaner API and less code to maintain.

However, we've ended up with a lot of scripts doing similar things, so there has been an effort more recently to introduced some more general code to help make these behaviours
easier.

If you are writing a script that:

- iterates through all of something from the API (eg "get all buyer users")
- transforms specific values in your data collection (eg "get the domain name of user email addresses")
- merges data between two different models (eg "get number of draft briefs per buyer user")
- getting counts in one-to-many relationships (eg "get number of users per supplier")

then you should be *strongly biased* to using the following reusable code.

#### `modeltrawler.py`

Iterates through a set of models.
Returns only specified keys (including nested keys).
Default behaviour is to return all keys.

```python
mt = ModelTrawler('users', data_api_client)
mt.get_data(keys=('id', 'emailAddress', ('supplier', 'name'), 'role'))
data.to_csv(filename, index=False, encoding='utf-8')
```

CSV output
```csv
...
1,don@scdp.biz,Stanley Cooper Draper Price, supplier
2,andy@dm.info,Dunder Mifflin, supplier
3,paul@gov.uk,,buyer
...
```

#### ``queries.py``

This file contains the logic you need for joining files, as well as sorting, counting or processing values.

```python
# assumes `suppliers.csv` and `users.csv` exist in the `./data` directory
data = join(
    ({'model': 'suppliers', 'key': 'id'},
     {'model': 'users', 'key': "supplierId"}),
    './data'
)
data = data[('supplierId', 'name', 'dunsNumber', 'emailAddress')]
data.to_csv(filename, index=False, encoding='utf-8')
```

CSV output
```csv
...
101,Stanley Cooper Draper Price,123456789,don@scdp.biz
101,Stanley Cooper Draper Price,123456789,peggy@scdp.biz
102,Dunder Mifflin,111111119,andy@dm.info
...
```

#### `get-model-data.py`

We want to be able to write everything as config dictionaries and then run it all through the same generalised logic. The `get-model-data.py` script gives a good example of how to do this.
